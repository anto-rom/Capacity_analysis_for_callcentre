{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d52105cb",
   "metadata": {},
   "source": [
    "# Call Center Capacity Analysis\n",
    "This notebook analyzes historical call performance data to forecast workload and estimate required staffing levels.\n",
    "\n",
    "## Objectives\n",
    "- Load and inspect historical performance data\n",
    "- Clean and prepare data for analysis\n",
    "- Explore trends by language, queue, and time\n",
    "- Forecast future workload\n",
    "- Estimate required agent capacity per day, language, and queue\n",
    "- Export key results for operational planning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fe6a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd95c83",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0054db1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'C:/Users/anto-/OneDrive/Desktop/PracticasMaster/call_performance.xlsx'\n",
    "call_data = pd.read_excel(file_path)\n",
    "call_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae2298b",
   "metadata": {},
   "source": [
    "## Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18eab5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_data.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5de734",
   "metadata": {},
   "source": [
    "## Data Cleaning & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf858f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Block 4\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Leer el Excel\n",
    "df = pd.read_excel(\"call_performance.xlsx\")\n",
    "\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Agrupar por fecha y contar llamadas\n",
    "calls_per_day = df.groupby(df['Date'].dt.date).size().reset_index(name='call_count')\n",
    "\n",
    "# --- Detecci칩n de outliers con IQR ---\n",
    "Q1 = calls_per_day['call_count'].quantile(0.25)\n",
    "Q3 = calls_per_day['call_count'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filtrar d칤as outlier\n",
    "outliers = calls_per_day[(calls_per_day['call_count'] < lower_bound) |\n",
    "                         (calls_per_day['call_count'] > upper_bound)]\n",
    "\n",
    "print(\"游늵 D칤as con n칰mero de llamadas fuera del rango esperado (outliers):\")\n",
    "print(outliers)\n",
    "\n",
    "# --- Gr치fico con outliers destacados ---\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(data=calls_per_day, x='Date', y='call_count', marker='o', label='Llamadas por d칤a')\n",
    "plt.scatter(outliers['Date'], outliers['call_count'], color='red', label='Outliers', zorder=5)\n",
    "plt.axhline(upper_bound, color='red', linestyle='--', label='L칤mite superior')\n",
    "plt.axhline(lower_bound, color='orange', linestyle='--', label='L칤mite inferior')\n",
    "plt.title('N칰mero de llamadas por d칤a con detecci칩n de outliers')\n",
    "plt.xlabel('Fecha')\n",
    "plt.ylabel('Cantidad de llamadas')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afea0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Block 5\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Leer datos\n",
    "df = pd.read_excel(\"call_performance.xlsx\")\n",
    "\n",
    "# Eliminar filas con valores nulos relevantes\n",
    "df = df[['Language', 'call_duration']].dropna()\n",
    "\n",
    "# --- Eliminar outliers por grupo usando IQR ---\n",
    "def remove_outliers_iqr(group):\n",
    "    Q1 = group.quantile(0.25)\n",
    "    Q3 = group.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "    return group[(group >= lower) & (group <= upper)]\n",
    "\n",
    "df['clean_duration'] = df.groupby('Language')['call_duration'].transform(remove_outliers_iqr)\n",
    "df_clean = df.dropna(subset=['clean_duration'])\n",
    "\n",
    "# --- Calcular IC por idioma usando .agg() ---\n",
    "z_score = norm.ppf(0.975)  # 95% confidence level\n",
    "\n",
    "summary = df_clean.groupby('Language')['clean_duration'].agg(['count', 'mean', 'std']).reset_index()\n",
    "summary['margin_error'] = z_score * (summary['std'] / np.sqrt(summary['count']))\n",
    "summary['ci_lower'] = summary['mean'] - summary['margin_error']\n",
    "summary['ci_upper'] = summary['mean'] + summary['margin_error']\n",
    "\n",
    "# Mostrar tabla resumen\n",
    "print(\"游늵 Intervalo de confianza (95%) para la duraci칩n de llamada por idioma:\")\n",
    "print(summary)\n",
    "\n",
    "# --- Visualizaci칩n ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.errorbar(summary['Language'], summary['mean'],\n",
    "             yerr=summary['margin_error'], fmt='o', capsize=5, color='blue')\n",
    "plt.title('95% Confidence Interval of Call Duration by Language (Outliers Removed)')\n",
    "plt.xlabel('Language')\n",
    "plt.ylabel('Call Duration (mean 췀 margin of error)')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b295d1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Block 6\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# Cargar datos\n",
    "df = pd.read_excel(\"call_performance.xlsx\", sheet_name=\"Call performance\")\n",
    "\n",
    "# Preprocesamiento\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['weekday'] = df['Date'].dt.day_name()\n",
    "df['hour'] = pd.to_datetime(df['call_hour'], format='%H:%M', errors='coerce').dt.strftime('%H:00')\n",
    "df['call_count'] = 1\n",
    "\n",
    "# Filtrar outliers usando el m칠todo IQR\n",
    "def remove_outliers(group):\n",
    "    q1 = group['call_count'].quantile(0.25)\n",
    "    q3 = group['call_count'].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    mask = (group['call_count'] >= q1 - 1.5 * iqr) & (group['call_count'] <= q3 + 1.5 * iqr)\n",
    "    return group[mask]\n",
    "\n",
    "# Agregar conteo diario para cada combinaci칩n\n",
    "daily_calls_lang = df.groupby(['weekday', 'hour', 'Language', 'Date']).agg({'call_count': 'sum'}).reset_index()\n",
    "daily_calls_queue = df.groupby(['weekday', 'hour', 'queue_name', 'Date']).agg({'call_count': 'sum'}).reset_index()\n",
    "\n",
    "# Eliminar outliers\n",
    "filtered_lang = daily_calls_lang.groupby(['weekday', 'hour', 'Language']).apply(remove_outliers).reset_index(drop=True)\n",
    "filtered_queue = daily_calls_queue.groupby(['weekday', 'hour', 'queue_name']).apply(remove_outliers).reset_index(drop=True)\n",
    "\n",
    "# Calcular promedio sin outliers\n",
    "avg_calls_lang = filtered_lang.groupby(['weekday', 'hour', 'Language'])['call_count'].mean().reset_index()\n",
    "avg_calls_queue = filtered_queue.groupby(['weekday', 'hour', 'queue_name'])['call_count'].mean().reset_index()\n",
    "\n",
    "# Renombrar columna de resultado\n",
    "avg_calls_lang = avg_calls_lang.rename(columns={'call_count': 'No. Calls'})\n",
    "avg_calls_queue = avg_calls_queue.rename(columns={'call_count': 'No. Calls'})\n",
    "\n",
    "# Guardar resultados en Excel\n",
    "with pd.ExcelWriter(\"avg_calls_by_language_and_queue.xlsx\") as writer:\n",
    "    avg_calls_lang.to_excel(writer, sheet_name=\"By Language\", index=False)\n",
    "    avg_calls_queue.to_excel(writer, sheet_name=\"By Queue\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062c91db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Block 7\n",
    "# ========================\n",
    "# ESTANDARIZACI칍N Y AN츼LISIS DE DATOS\n",
    "# ========================\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ------------------------\n",
    "# 1. Cargar los archivos\n",
    "# ------------------------\n",
    "\n",
    "call_df = pd.read_excel(\"call_performance.xlsx\")\n",
    "tickets_df = pd.read_excel(\"Incoming tickets last year.xlsx\")\n",
    "\n",
    "# ------------------------\n",
    "# 2. Estandarizar llamadas\n",
    "# ------------------------\n",
    "\n",
    "call_df['Month'] = pd.to_datetime(call_df['Date']).dt.strftime('%B')\n",
    "call_df['Hour'] = pd.to_datetime(call_df['call_hour'], errors='coerce').dt.hour\n",
    "calls_grouped = call_df.groupby(['Month', 'Language']).agg(\n",
    "    Average_Call_Duration=('call_duration', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# ------------------------\n",
    "# 3. Estandarizar tickets\n",
    "# ------------------------\n",
    "\n",
    "tickets_df['Month'] = tickets_df['Month'].str.strip()\n",
    "tickets_grouped = tickets_df.groupby(['Month', 'Weekday']).size().reset_index(name='No_Tickets')\n",
    "\n",
    "# ------------------------\n",
    "# 4. Crear pivotes para heatmaps\n",
    "# ------------------------\n",
    "\n",
    "month_order = ['January', 'February', 'March', 'April', 'May', 'June',\n",
    "               'July', 'August', 'September', 'October', 'November', 'December']\n",
    "\n",
    "calls_pivot = calls_grouped.pivot(index='Language', columns='Month', values='Average_Call_Duration')\n",
    "calls_pivot = calls_pivot.reindex(columns=month_order, fill_value=0)\n",
    "\n",
    "tickets_pivot = tickets_grouped.pivot(index='Weekday', columns='Month', values='No_Tickets')\n",
    "tickets_pivot = tickets_pivot.reindex(columns=month_order, fill_value=0)\n",
    "\n",
    "# ------------------------\n",
    "# 5. Visualizaci칩n: Heatmaps (Idioma y D칤a Semana)\n",
    "# ------------------------\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(calls_pivot, annot=True, fmt=\".1f\", cmap=\"YlGnBu\")\n",
    "plt.title(\"Average Call Duration by Language and Month\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Language\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(tickets_pivot, annot=True, fmt=\".0f\", cmap=\"OrRd\")\n",
    "plt.title(\"Number of Tickets by Weekday and Month\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Weekday\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ------------------------\n",
    "# 6. An치lisis adicional por Queue\n",
    "# ------------------------\n",
    "\n",
    "queue_grouped = call_df.groupby(['Month', 'queue_name']).agg(\n",
    "    Avg_Duration=('call_duration', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "queue_pivot = queue_grouped.pivot(index='queue_name', columns='Month', values='Avg_Duration')\n",
    "queue_pivot = queue_pivot.reindex(columns=month_order, fill_value=0)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(queue_pivot, annot=True, fmt=\".1f\", cmap=\"PuBuGn\")\n",
    "plt.title(\"Average Call Duration by Queue and Month\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Queue Name\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ------------------------\n",
    "# 7. An치lisis por franja horaria\n",
    "# ------------------------\n",
    "\n",
    "hour_grouped = call_df.groupby(['Month', 'Hour']).size().reset_index(name='No_Calls')\n",
    "hour_pivot = hour_grouped.pivot(index='Hour', columns='Month', values='No_Calls')\n",
    "hour_pivot = hour_pivot.reindex(columns=month_order, fill_value=0)\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.heatmap(hour_pivot, annot=True, fmt=\".0f\", cmap=\"YlOrBr\")\n",
    "plt.title(\"Number of Calls by Hour and Month\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Hour of Day\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ------------------------\n",
    "# 8. An치lisis de correlaci칩n\n",
    "# ------------------------\n",
    "\n",
    "calls_month_avg = calls_grouped.groupby('Month')['Average_Call_Duration'].mean()\n",
    "tickets_month_sum = tickets_grouped.groupby('Month')['No_Tickets'].sum()\n",
    "\n",
    "correlation_df = pd.DataFrame({\n",
    "    'Average_Call_Duration': calls_month_avg,\n",
    "    'Total_Tickets': tickets_month_sum\n",
    "}).reindex(index=month_order)\n",
    "\n",
    "correlation_matrix = correlation_df.corr()\n",
    "\n",
    "# Mostrar tabla resumen y matriz de correlaci칩n\n",
    "print(\"=== Tabla Resumen de Correlaci칩n ===\")\n",
    "display(correlation_df.reset_index())\n",
    "\n",
    "print(\"\\n=== Matriz de Correlaci칩n ===\")\n",
    "display(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9414c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Block 8\n",
    "# ========================================\n",
    "# PREDICCI칍N DE DEMANDA Y NECESIDADES DE PERSONAL\n",
    "# ========================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# ------------------------\n",
    "# 1. Carga de archivos\n",
    "# ------------------------\n",
    "\n",
    "call_df = pd.read_excel(\"call_performance.xlsx\")\n",
    "tickets_df = pd.read_excel(\"Incoming tickets last year.xlsx\")\n",
    "production_df = pd.read_excel(\"Production.xlsx\")\n",
    "\n",
    "# ------------------------\n",
    "# 2. Preprocesar llamadas\n",
    "# ------------------------\n",
    "\n",
    "call_df['Date'] = pd.to_datetime(call_df['Date'])\n",
    "calls_per_day = call_df.groupby('Date').size().reset_index(name='No_Calls')\n",
    "\n",
    "# ------------------------\n",
    "# 3. Preprocesar tickets\n",
    "# ------------------------\n",
    "\n",
    "tickets_df['Closed Date'] = pd.to_datetime(tickets_df['Closed Date'], dayfirst=True, errors='coerce')\n",
    "tickets_per_day = tickets_df.groupby('Closed Date').size().reset_index(name='No_Tickets')\n",
    "tickets_per_day.rename(columns={'Closed Date': 'Date'}, inplace=True)\n",
    "\n",
    "# ------------------------\n",
    "# 4. Consolidar volumen hist칩rico diario\n",
    "# ------------------------\n",
    "\n",
    "volume_df = pd.merge(calls_per_day, tickets_per_day, on='Date', how='outer').fillna(0)\n",
    "volume_df['Total_Items'] = volume_df['No_Calls'] + volume_df['No_Tickets']\n",
    "\n",
    "# Rellenar d칤as faltantes\n",
    "date_range = pd.date_range(start=volume_df['Date'].min(), end=volume_df['Date'].max())\n",
    "volume_df = volume_df.set_index('Date').reindex(date_range).fillna(0).rename_axis('Date').reset_index()\n",
    "\n",
    "# ------------------------\n",
    "# 5. Modelado SARIMAX para predicci칩n diaria\n",
    "# ------------------------\n",
    "\n",
    "ts = volume_df.set_index('Date')['Total_Items']\n",
    "\n",
    "model = SARIMAX(ts, order=(1, 1, 1), seasonal_order=(1, 1, 1, 7),\n",
    "                enforce_stationarity=False, enforce_invertibility=False)\n",
    "results = model.fit(disp=False)\n",
    "\n",
    "future_dates = pd.date_range(start=ts.index[-1] + pd.Timedelta(days=1), end=\"2025-12-31\")\n",
    "forecast = results.get_forecast(steps=len(future_dates)).predicted_mean.round().clip(lower=0)\n",
    "\n",
    "forecast_df = pd.DataFrame({'Date': future_dates, 'Predicted_Items': forecast.values})\n",
    "\n",
    "# ------------------------\n",
    "# 6. Simulaci칩n de personal requerido por SLA\n",
    "# ------------------------\n",
    "\n",
    "def calcular_agentes(pred_df, sla_target):\n",
    "    pred_df = pred_df.copy()\n",
    "    pred_df['Target_Items'] = pred_df['Predicted_Items'] * sla_target\n",
    "    pred_df['Agents_Required'] = (pred_df['Target_Items'] / 15).apply(np.ceil)\n",
    "    return pred_df[['Date', 'Predicted_Items', 'Agents_Required']]\n",
    "\n",
    "sim_80 = calcular_agentes(forecast_df, sla_target=0.80)\n",
    "sim_85 = calcular_agentes(forecast_df, sla_target=0.85)\n",
    "sim_90 = calcular_agentes(forecast_df, sla_target=0.90)\n",
    "\n",
    "# ------------------------\n",
    "# 7. Visualizaci칩n opcional\n",
    "# ------------------------\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(sim_85['Date'], sim_85['Agents_Required'], label='SLA 85%')\n",
    "plt.plot(sim_90['Date'], sim_90['Agents_Required'], label='SLA 90%', linestyle='--')\n",
    "plt.plot(sim_80['Date'], sim_80['Agents_Required'], label='SLA 80%', linestyle=':')\n",
    "plt.title('Agents Required per Day by SLA Target')\n",
    "plt.ylabel('Agents')\n",
    "plt.xlabel('Date')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ------------------------\n",
    "# 8. Producci칩n diaria hist칩rica (solo si se necesita validar capacidad real)\n",
    "# ------------------------\n",
    "\n",
    "production_df['Case Date'] = pd.to_datetime(production_df['Case Date/Time Last Modified'].str.split(',').str[0], dayfirst=True)\n",
    "daily_production = production_df.groupby('Case Date').size().reset_index(name='Items_Resolved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6997e841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Block 9\n",
    "# ==========================================\n",
    "# FORECAST Y NECESIDADES POR IDIOMA Y QUEUE\n",
    "# ==========================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# ------------------------\n",
    "# 1. Cargar datos\n",
    "# ------------------------\n",
    "\n",
    "call_df = pd.read_excel(\"call_performance.xlsx\")\n",
    "call_df['Date'] = pd.to_datetime(call_df['Date'])\n",
    "call_df['Hour'] = pd.to_datetime(call_df['call_hour'], errors='coerce').dt.hour\n",
    "\n",
    "# ------------------------\n",
    "# 2. Generar granularidad\n",
    "# ------------------------\n",
    "\n",
    "grouped = call_df.groupby(['Date', 'Language', 'queue_name']).size().reset_index(name='Volume')\n",
    "\n",
    "# ------------------------\n",
    "# 3. Forecast por combinaci칩n Language + Queue\n",
    "# ------------------------\n",
    "\n",
    "forecast_results = []\n",
    "\n",
    "for (lang, queue), df_subset in tqdm(grouped.groupby(['Language', 'queue_name'])):\n",
    "    df_ts = df_subset.set_index('Date').resample('D').sum().reindex(\n",
    "        pd.date_range(df_subset['Date'].min(), df_subset['Date'].max()), fill_value=0\n",
    "    )\n",
    "    \n",
    "    ts = df_ts['Volume']\n",
    "    \n",
    "    try:\n",
    "        model = SARIMAX(ts, order=(1, 1, 1), seasonal_order=(1, 1, 1, 7),\n",
    "                        enforce_stationarity=False, enforce_invertibility=False)\n",
    "        results = model.fit(disp=False)\n",
    "        \n",
    "        future_dates = pd.date_range(start=ts.index[-1] + pd.Timedelta(days=1), end=\"2025-12-31\")\n",
    "        forecast = results.get_forecast(steps=len(future_dates)).predicted_mean.round().clip(lower=0)\n",
    "\n",
    "        temp_df = pd.DataFrame({\n",
    "            'Date': future_dates,\n",
    "            'Language': lang,\n",
    "            'Queue': queue,\n",
    "            'Predicted_Items': forecast.values\n",
    "        })\n",
    "\n",
    "        forecast_results.append(temp_df)\n",
    "        \n",
    "    except:\n",
    "        continue\n",
    "\n",
    "forecast_df = pd.concat(forecast_results, ignore_index=True)\n",
    "\n",
    "# ------------------------\n",
    "# 4. Funci칩n para estimar agentes requeridos\n",
    "# ------------------------\n",
    "\n",
    "def calcular_agentes_por_comb(forecast_df, sla_target):\n",
    "    df = forecast_df.copy()\n",
    "    df['Target_Items'] = df['Predicted_Items'] * sla_target\n",
    "    df['Agents_Required'] = np.ceil(df['Target_Items'] / 15)\n",
    "    return df[['Date', 'Language', 'Queue', 'Predicted_Items', 'Agents_Required']]\n",
    "\n",
    "# ------------------------\n",
    "# 5. Generar simulaciones SLA\n",
    "# ------------------------\n",
    "\n",
    "sim_sla_80 = calcular_agentes_por_comb(forecast_df, 0.80)\n",
    "sim_sla_85 = calcular_agentes_por_comb(forecast_df, 0.85)\n",
    "sim_sla_90 = calcular_agentes_por_comb(forecast_df, 0.90)\n",
    "\n",
    "# ------------------------\n",
    "# 6. Exportar a Excel\n",
    "# ------------------------\n",
    "\n",
    "with pd.ExcelWriter(\"Forecast_Language_Queue_Agents.xlsx\", engine='xlsxwriter') as writer:\n",
    "    forecast_df.to_excel(writer, sheet_name=\"Forecast_Raw\", index=False)\n",
    "    sim_sla_80.to_excel(writer, sheet_name=\"Agents_SLA_80\", index=False)\n",
    "    sim_sla_85.to_excel(writer, sheet_name=\"Agents_SLA_85\", index=False)\n",
    "    sim_sla_90.to_excel(writer, sheet_name=\"Agents_SLA_90\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeec60ec",
   "metadata": {},
   "source": [
    "## Export Results to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b296d286",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'call_analysis_output.xlsx'\n",
    "# You can customize which DataFrames to export here.\n",
    "# Example: forecast_df.to_excel(output_file, index=False)\n",
    "print(f\"Results would be saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a998b02f",
   "metadata": {},
   "source": [
    "## Forecasting Demand and Estimating Staffing Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de883ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This section builds a time series forecasting model using SARIMAX to predict the volume of items (calls + tickets)\n",
    "until the end of 2025. Based on the forecasted demand, it simulates how many agents are needed per language\n",
    "and queue, ensuring that a target percentage of items are resolved within 2 days.\n",
    "\"\"\"\n",
    "\n",
    "# Ensure the \"Date\" column is datetime\n",
    "call_data['Date'] = pd.to_datetime(call_data['Date'])\n",
    "# Aggregate data per day, language, and queue\n",
    "daily_volume = call_data.groupby(['Date', 'Language', 'queue_name']).size().reset_index(name='volume')\n",
    "# Create complete date range\n",
    "full_range = pd.date_range(start=daily_volume['Date'].min(), end='2025-12-31', freq='D')\n",
    "# Pivot for forecasting per language and queue\n",
    "pivot_volume = daily_volume.pivot_table(index='Date', columns=['Language', 'queue_name'], values='volume', fill_value=0)\n",
    "\n",
    "# Forecasting setup (example for one language/queue combo)\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "forecast_results = {}\n",
    "for col in pivot_volume.columns:\n",
    "    ts = pivot_volume[col]\n",
    "    try:\n",
    "        model = SARIMAX(ts, order=(1,1,1), seasonal_order=(1,1,1,7), enforce_stationarity=False, enforce_invertibility=False)\n",
    "        result = model.fit(disp=False)\n",
    "        forecast = result.get_forecast(steps=(len(full_range) - len(ts)))\n",
    "        forecast_values = forecast.predicted_mean\n",
    "        forecast_index = full_range[-len(forecast_values):]\n",
    "        forecast_results[col] = pd.Series(forecast_values.values, index=forecast_index)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "# Combine forecasts\n",
    "forecast_df = pd.DataFrame(forecast_results).fillna(0).astype(int)\n",
    "forecast_df.index.name = 'Date'\n",
    "forecast_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ee8999",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Simulates the required number of agents per day to achieve different resolution targets.\n",
    "Assumptions:\n",
    "- Each agent can handle 15 items per day.\n",
    "- Items should be resolved within 2 days for 80%, 85%, and 90% of the volume.\n",
    "\"\"\"\n",
    "\n",
    "required_agents = {}\n",
    "for target in [0.8, 0.85, 0.9]:\n",
    "    needed = (forecast_df.rolling(2).sum() * target / 15).apply(np.ceil)\n",
    "    needed.columns = [f'{lang}_{queue}_agents_{int(target*100)}pct' for lang, queue in needed.columns]\n",
    "    required_agents[target] = needed\n",
    "\n",
    "# Combine agent estimates\n",
    "agents_df = pd.concat(required_agents.values(), axis=1)\n",
    "agents_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7118c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export forecast and capacity planning\n",
    "with pd.ExcelWriter('forecast_and_capacity.xlsx') as writer:\n",
    "    forecast_df.to_excel(writer, sheet_name='Forecast')\n",
    "    agents_df.to_excel(writer, sheet_name='Agents_Needed')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
